```
kubectl config get-clusters|grep -v NAME|tee /opt/course/1/contexts

echo kubectl config current-context|tee /opt/course/1/context_default_kubectl.sh

echo 'grep current .kube/config|cut -d\  -f2'|tee /opt/course/1/context_default_no_kubectl.sh

kubectl run --dry-run=client -oyaml --image httpd:2.4.41-alpine -n default pod1|tee 02.yaml

kubectl get no --show-labels|grep control-plane

kubectl taint no cluster1-controlplane1 node-role.kubernetes.io/control-plane:NoSchedule-
```
```
apiVersion: v1
kind: Pod
metadata:
  name: pod1
  namespace: default
spec:
  containers:
  - image: httpd:2.4.41-alpine
    name: pod1-container
  nodeSelector:
    node-role.kubernetes.io/control-plane: ''
  tolerations:
  - key: node-role.kubernetes.io/control-plane
    effect: NoSchedule
```
```
kubectl -n project-c13 get po o3db-0 -oyaml|grep ownerReferences: -A6

kubectl -n project-c13 scale --replicas 1 sts o3d

kubectl run -n default --dry-run=client -oyaml ready-if-service-ready --image nginx:1.16.1-alpine|tee 04.yaml

kubectl explain po.spec.containers.livenessProbe.exec
```
```
apiVersion: v1
kind: Pod
metadata:
  name: ready-if-service-ready
  namespace: default
spec:
  containers:
  - image: nginx:1.16.1-alpine
    name: ready-if-service-ready
    livenessProbe:
      exec:
        command:
        - "true"
    readinessProbe:
      exec:
        command:
        - "wget -T2 -O- http://service-am-i-ready:80"
```
